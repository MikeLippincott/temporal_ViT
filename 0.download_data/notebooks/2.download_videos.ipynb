{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook downloads timelapse videos of landscapes from [Martin Setvak's website](https://www.setvak.cz/timelapse/timelapse.html).\n",
    "The purpose of downloading these videos is to use them as training data for a temporal Vision Transformer (ViT) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to where the data will be stored\n",
    "# this is hardcoded and an absolute path this must be changed for your system\n",
    "output_path = pathlib.Path(\n",
    "    \"/home/lippincm/Desktop/18TB/timelapse_data_landscapes/raw_videos\"\n",
    ").resolve()\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a web scraper to capture the video URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the web scraping\n",
    "url = \"https://www.setvak.cz/timelapse/\"\n",
    "list_of_years = [\n",
    "    2024,\n",
    "    2023,\n",
    "    2022,\n",
    "    2021,\n",
    "    2020,\n",
    "    2019,\n",
    "    2018,\n",
    "    2017,\n",
    "    2016,\n",
    "    2015,\n",
    "    \"2015a_Tenerife\",\n",
    "    2014,\n",
    "    2013,\n",
    "    \"2013a_HoheTauern\",\n",
    "    2012,\n",
    "    2011,\n",
    "    2010,\n",
    "    \"2010a_USA\",\n",
    "    2009,\n",
    "    2008,\n",
    "    2007,\n",
    "    2006,\n",
    "]\n",
    "reponses_dict = {}\n",
    "for year in list_of_years:\n",
    "    reponses_dict[year] = requests.get(f\"{url}{year}.html\")\n",
    "    reponses_dict[year].raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220620_0635-0720utc_roll-cloud_Kacerov_x264_1920x1080.mp4</a>   (54 MB) <br/>\n",
      "20220916_0620-0920utc_Cachtice_1920x1080_x264.mp4</a>  (156 MB)   <br/>\n",
      "20221027_0500-0810utc_Hradcany_Mala-Strana_Petrin_1920x1080_x264.mp4</a>  (160 MB)  <br/>\n",
      "20210427_1730-1930utc_Praha_1920x1080_H264.mp4</a>   (70 MB)<br/>\n",
      "20210629_1900-1945utc_Kacerov_shelf-cloud_1728x1080_H264.mp4</a>   (42 MB)<br/>\n",
      "20210821_1107-1241utc_Pasterze-Grossglockner_1920x1080_H264.mp4</a>   (126 MB)   <br/>\n",
      "20200820_1715_20200821-0555utc_Jankovska-Lhota_x264_1800x1080.mp4</a>  (123 MB)   <br/>\n",
      "are identical to those stored as <b>.mp4</b> (here as standard H.264\n",
      "are identical to those stored as <b>.mp4</b> (here as standard H.264\n",
      "</span>20130802_2135-2245utc_Rauris.mp4</a>  (7 MB,\n",
      "20130807_0740-0830utc_Edelweissspitze.mp4</a>  (39 MB, 1280x720,\n",
      "1757-1811utc_Radostovice.mp4</a>  (17 MB, 1080x720,\n"
     ]
    }
   ],
   "source": [
    "# parse the html from the dictionary\n",
    "list_of_links = []\n",
    "for year in reponses_dict:\n",
    "    if reponses_dict[year].status_code != 200:\n",
    "        print(f\"Error: {year}\")\n",
    "        continue\n",
    "    soup = BeautifulSoup(reponses_dict[year].content, \"html.parser\")\n",
    "    # convert the soup to a string\n",
    "    soup_str = str(soup)\n",
    "    for line in soup_str.split(\"\\n\"):\n",
    "        if str(line).find(\".mp4\") != -1:\n",
    "            if \"href\" not in line:\n",
    "                print(line)\n",
    "            else:\n",
    "                list_of_links.append(\n",
    "                    f\"https://www.setvak.cz/timelapse/{BeautifulSoup(line, 'html.parser').find_all('a')[0].get('href')}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in list_of_links:\n",
    "    if \".mp4\" not in link:\n",
    "        # remove the link from the list\n",
    "        list_of_links.remove(link)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [00:00<00:00, 403.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404 Client Error: Not Found for url: https://www.setvak.cz/timelapse/2013/20130509_0816-0850utc_Jizerka.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download the videos carefully - this will take a while and a lot of space\n",
    "# we do not want to download the same video twice\n",
    "# we do not want to download the video if it is already in the folder\n",
    "# we do not want to get blacklisted either\n",
    "for link in tqdm.tqdm(list_of_links):\n",
    "    # get the name of the video\n",
    "    video_name = link.split(\"/\")[-1]\n",
    "    # set the path to the video file\n",
    "    video_path = output_path / f\"{video_name}\"\n",
    "    # check if the video is already downloaded\n",
    "    if video_path.exists():\n",
    "        continue\n",
    "    # download the video\n",
    "    try:\n",
    "        video_response = requests.get(link)\n",
    "        video_response.raise_for_status()\n",
    "        # save the video\n",
    "        with open(video_path, \"wb\") as f:\n",
    "            f.write(video_response.content)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(\n",
    "        np.random.randint(1, 5)\n",
    "    )  # sleep for a random amount of time to avoid getting blacklisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.cs.cmu.edu/~walt/license.html\n",
    "WALT_LINK = \"https://drive.google.com/drive/folders/1qb7EUiMJ_fCjqDn2b6pos9QUVlt5L0Rr?usp=sharing\"\n",
    "\n",
    "# lastly, download the WALT dataset manually from the google drive link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the moments in time MiT dataset\n",
    "* https://arxiv.org/abs/1801.03150 - Mathew Monfort et al. \"Moments in Time Dataset: one million videos for event understanding\" 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiT_url = \"http://moments.csail.mit.edu/splits/Moments_in_Time_Raw_v2.zip\"\n",
    "# download manually"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
